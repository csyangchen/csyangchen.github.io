---
title: RAG简介
---

LLM当道, 以及大力出奇迹的时代, "凡人"还能做什么:
- PE / prompt engineering / 提示工程: 固定模型, 调整文化方式以得到更理想结果, 做一个循序善诱的好老师 (OR 审讯人员)
  - FSL few shot learning
  - COT
  - ...
- SFT / supervised fine tuning / 微调: 投喂私人精酿数据, 以期在关心任务上效果提升, 做一个勤于补课集训, 善于考前突击的学生
  - 有没有 unsupervised fine tuning ? 那叫 unsupervised pre-training, LLM都是给到足够的条件后自学成才的

# LLM模型缺点

回答缺少时效性, 因为训练投喂的数据是静态的过时的. 作为个人智能助手的角色时, 这一点是不能接受的.
由于一次训练开销过大, 耗时过长, 也不太可能通过定期训练弥补.

结果幻觉问题, 即一本正经的胡说八道. 我可以接受你诚实的说不知道, 但是不可以胡编乱驺骗我.
不可控的生成, 说的话类似于做梦, 罔顾事实非常奇幻, 或者像幼童, 因为小孩更容易胡编乱造事实以合理化自己的行为, 说话不可信.
不同于梦呓, 难以从结果上判定是否可信.
因此不能用于如法律问答, 医疗诊断等严肃应用场景.
短期内的应用, 多落在(文科类型)文章创作, 陪聊机器人等, 错误不会导致严重后果场景.

插眼: COT能否缓解LLM的幻觉问题?

我们需要什么样的智能体? 能提供有时效的信息, 并可提供信息来源作证结论.

我们利用LLM的什么能力?

- 语文能力: 阅读理解, 摘要能力, 写作能力
- 逻辑推理: 基础数学计算能力
- 科学素养: 基础知识储备, 认为短期不会变化的基础事实, 如科学原理, 历史, 地理等

总而言之, 合格的LLM应当类似一个优秀的高中毕业生. 这也是为啥LLM评测用SAT之类做.

LLM不具有什么能力?

- 无限的信息存储空间, 自然不能做到对于投喂数据的过目不忘能力
- 新信息的捕获能力

因此我们需要让LLM"联网"看世界.

# 日常联网检索解决问题的痛点

从个人解决经验来看, 有时解决完一个问题, 回头一看, 浏览器打开几十个网页, 不断排除似是而非的答案, 问题条件不匹配的答案, 并验证可行性.

时间都浪费再哪儿了? 
- 问题相关检索关键词的尝试
- 等待网页打开渲染
- 阅读并忽略无关内容, 如广告, 网页导航元素等, 忽略文章中的各种废话, 好一点的搜索引擎功能跳转时直接高亮对应高亮词, 减少二次快速定位成本
- 时效性验证, 尤其很多导航办事指南, 都是过时的, 优先找更新的内容
- 浏览过程中的分心, 一个网页链接诱惑太多了, 或者说跟着推荐内容点击, 一下子又扇出更多需要看的内容
- 对内容的正确性进行尝试验证, 可能本身就答案错误, 或者场景不一致导致不适用, 一些问答网站通过踩赞等众包手段来降低这一缓解的试错成本
- 判定是否重复的内容, 尤其在新闻方面, 通稿太多, 找不到提供更新内容的文章

如何的出答案?
- 有类似问题的答案, 做契合性筛选. 如"佛山一日游如何推荐", 人均价格, 时间要求, 体力要求, 是否要自驾等筛选项逐一过滤掉
- 置信度评分排序, 如技术内容, stackoverflow上的比CSDN的更可信, 旅游方面认为小红书上软文更少更可信, 等
- 来源独立性确认, 独立来源信息互相印证, 则更可信

若无类似问题答案的, 需要做问题拆解并不断总结, 考验基本的问题拆分能力.

工作量在于对于检索结果的阅读过滤去重, 质量甄别.

问题的根源在哪里? 传统搜索引擎返回了太多的东西, 而我们需要的只是一个答案, 以及进一步, 这个答案是如何推理得到或者依赖的论据信息是哪些.
只是告诉了这里面可能有你要的东西, 而没有整合信息直接给到答案. 顺着一篇论文的引用去读开, 可以学会整个世界, 而你的时间和精力耗费不起.

我们需要怎样的知识助理? 一个爱看报跟得上时代的, 不装逼不吹牛的私人老师.
问问题先说结论, 再引经据典.
如果建立起了对于助理的信息, 则很少需要去自行验证信息来源可靠性以及推导答案的呵护逻辑性, 从而节省精力.

知识助理的动作
- 理解问题
- 查找信息
- 生成回答
- 后续展开

# 例子及产品评测

先日常调戏一遍ChatGPT

```
绿光是谁唱的?
 → [chatgpt] ←
绿光是由华语歌手李宇春演唱的。这首歌曲是由李宇春演唱的电视剧《何以笙箫默》的插曲，成为了该剧的代表性歌曲之一。

三国演义中张辽在第几回第一次出现?
$🤖️ → [chatgpt] ←
张辽在三国演义小说中第一次出现是在第三回，他在那一回中被曹操招募为麾下名将，并在白马之围中表现出色，击败了袁绍的将领高览和张郃。

三国演义里比司马懿活得久的角色有哪些?
🤖️ → [chatgpt] ←
三国演义中，活得比司马懿久的角色有不少，以下是其中的一些：
孙权：孙权是三国时期东吴的开国皇帝，他在位期间，东吴逐渐壮大，对抗曹魏和蜀汉。孙权在位56年，比司马懿长寿。
刘备：刘备是三国时期蜀汉的开国皇帝，他在位期间，蜀汉逐渐壮大，对抗曹魏和东吴。刘备在位23年，比司马懿短寿，但是他在三国演义中已经过世。
诸葛亮：诸葛亮是蜀汉的重要谋臣和政治家，他在位期间曾经多次出使吴国，协助刘备对抗曹魏。他在蜀汉丞相期间，处理政务有方，开创蜀汉的文治。诸葛亮逝世后，蜀汉逐渐没落，但他的名声却在历史中留了下来。
姜维：姜维是蜀汉的将领，他曾经多次出征，被赞誉为“锦马超”。姜维在刘禅时期期间，曾经多次阻止蜀汉投降曹魏。姜维在三国演义中死于曹魏的围攻，但是历史记录中，他比司马懿活得更久。
```

结合搜索的联网AI助手表现如何?

各传统搜索引擎已有落地, 根据提问概率触发. Google AI Overviews / New Bing / 微信搜索AI问答 / 百度搜索AI智能问答 / ... 等. 
简单问题, 如日期, 计算器, 天气等, 直接规则触发答案, 相当于搜索引擎加规则或者插件. 例子
- 距离春节还有多少天
- (42+8)/2
- 今日广州天气

结合搜索功能的AI知识助理, 国内推广比较猛的有
- [豆包](https://www.doubao.com/chat/)
- [KIMI](https://kimi.moonshot.cn/), 可以选择是否联网搜索, 不联网表现和ChatGPT"不相上下"
- ...

优点, 阅读时不用适配各种网站排版格式, 专注文字输出, 自动跳过网站广告内容. 从而跟专注内容.

缺点, 对于检索到不相关内容, 再融合答案时, 会出现奇怪的强行缝合答案, 需通过进一步细化提问方式解决.

生成速度更不上阅读速度时候, 会稍微卡效率. 如何商业化? 

由于检索互联网信息的"投毒", "怎么吃石头"这个问题反而是离线的LLM问答结果比较好. 由于开放联网的本质, 导致内容质量受控性差了.

# RAG

> 等等, 标题说RAG么, 前面这么多还没提到RAG.

RAG: Retrieval Augmented Generation, 检索增强生成

理解名字就知道大概怎么做了, 就是把检索的相关内容丢到提问里面, 从而得到更有时效, 更有证据的答案.
手段来说应该属于PE的范畴.

简言之, 可以视作提示工程: 每次问LLM前, 先检索可能相关的数据放入到PROMPT中后再问.

只利用LLM的基本逻辑推理能力, 忘记LLM存储的事实信息, 将需要分析的内容直接在PROMPT里面列出. 如
- 这是三国演义的目录: ... 请问第九回的标题是什么?
- 下面是三国演义的全文, 请问张辽在第几回第一次提及?

流程: 原始问题->检索->构建新的PROMPT->LLM提问->后处理

模块拆解
- 向量检索数据库: 内容的向量化表征, 并通过定义某种向量度量作为相似度或者相关性指标. ES等关键词检索也可以认为是广义的向量检索, 是定义在词包向量上的, 相关性得分作为度量
- LLM: 文档向量生成计算, 以及问答总结过程用
- 缝合逻辑, 前处理/后处理等规则

过程拆解
- 检索环节:
  - 数据爬取分析入库过程
  - 文档的切片, 如按照段落分, 按照句子分, 是否冗余切片等
  - 文档的标签化, 元信息, 如发生时间, 类别
- 查询环节: 问题理解, 检索内容, 返回TOP-K结果, reranking, 生成新的PROMPT, 提问并LLM得到附带来源链接的输出内容

RAG对于LLM的挑战: 更看重总结任务能力, 对于上下文有更高的要求

context window / 自主力机制决定了计算复杂度是窗口的平方关系, 各种相关优化(偷懒)手段

"Needle In a Haystack Test" for LLM RAG System: 长文本里面藏一个信息并针对性提问, 看LLM结果是否捕获该信息.

# 评价体系

从端到端的角度评价来说, 同LLM评价.
不过结果还依赖于检索相关性, 也可以拆成两阶段的评价, 前面的环节从检索排序评价体系 (AP/精度/召回/ranking evaluation/...)  

客观题, 有确定标号数据

主观题: 有参考答案, 相似度评分; 无参考答案, 人主观评价

评价维度:
- Relevancy
- Faithfulness
- Correctness

# RAG App Framework

[LangChain](https://python.langchain.com/v0.2/docs/tutorials/rag/)

[LlamaIndex](https://docs.llamaindex.ai/en/stable/)

[GraphRAG](https://microsoft.github.io/graphrag/)

# 我们业务落地的思考

化繁为简, 客户提出一个问题, 直接给出分析答案

- 阶段一, NLP2SQL: 自然语言提问跳转对应功能页面, 筛选项呈现结果
- 阶段二, 基于查询数据生成报告

例子:
- 上个月在印尼投放最多的应用是哪几个, 其中使用最多的素材是什么?
- 这周最近抖音电商美妆行业的投放量对比上周有什么变化, 是否有新的大牌玩家加入?

# PS: Transformer注意力机制回顾

意图: 模型结构里面固定习得的QKV以及Attention机制, 类似于联网后的检索环节?

```E += softmax(QK^T)*V*E```

E是整个句子(到目前为止)的嵌入空间向量

Q,K每一维认为是在问一个问题, 前段是每个问题的真假答案, V认为是每个问题对于信息细化权重, 并投影回嵌入空间

可以调的参数: 多少个头(每次可以多少问题), 多少层(一共可以问几次), 每次问之间是通过MLP链接, 理解为推理或者事实查找步骤

多头注意力: 多个问题的答案汇聚

例子: 猜人游戏
- 是男的么?
- 是港台的么?
- 是唱歌的么?
- 姓张么?
- ...

从不断问问题的答案中细化可能性或靠近真实答案

类似于结构化面试, 一箩筐问题, 这一轮答不好下一轮换一批简单的问题组合, 单这个问题回答的很出色加不少印象分, 等.

REF
- https://www.youtube.com/watch?v=9-Jl0dxWQs8
- https://www.youtube.com/watch?v=TRjq7t2Ms5I
